{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_dataframe(path):\n",
    "    # Initialize an empty list to store data from JSON files\n",
    "    data_list = []\n",
    "\n",
    "    # Traverse through all subdirectories and files\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                # Construct the full path to the JSON file\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Read data from the JSON file\n",
    "                with open(file_path, \"r\") as json_file:\n",
    "                    try:\n",
    "                        json_data = json.load(json_file)\n",
    "                        if \"symbolic_model\" in json_data:\n",
    "                            if isinstance(json_data[\"symbolic_model\"], list):\n",
    "                                sm = [\n",
    "                                    \"B\" + str(i) + \"*\" + ri\n",
    "                                    for i, ri in enumerate(json_data[\"symbolic_model\"])\n",
    "                                ]\n",
    "                                sm = \"+\".join(sm)\n",
    "                                json_data[\"symbolic_model\"] = sm\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_path}: {e}\")\n",
    "                        return\n",
    "\n",
    "                    # Append the data to the list\n",
    "                    data_list.append(json_data)\n",
    "\n",
    "    # Create a DataFrame from the list of JSON data\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.rename(columns={\"dataset\": \"dataset_name\"}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlb_BART_perm = json_to_dataframe(os.path.normpath(\"../results_blackbox/BART_perm\"))\n",
    "pmlb_BART_perm.rename(columns={\"col_idx\": \"idx_gse\"}, inplace=True)\n",
    "pmlb_BART_perm[\"idx_gse\"] = pmlb_BART_perm.apply(\n",
    "    lambda row: [] if row[\"failed\"] else row[\"idx_gse\"], axis=1\n",
    ")\n",
    "pmlb_BART_perm[\"SNR\"] = 0.0\n",
    "pmlb_BART_perm[\"n\"] = 0.0\n",
    "\n",
    "feather.write_feather(\n",
    "    pmlb_BART_perm,\n",
    "    os.path.normpath(\"../results_blackbox/pmlb_BART_perm.feather\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART VIP Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlb_BART_VIP = json_to_dataframe(os.path.normpath(\"../results_blackbox/BART_VIP\"))\n",
    "\n",
    "feather.write_feather(\n",
    "    pmlb_BART_VIP,\n",
    "    os.path.normpath(\"../results_blackbox/pmlb_BART_VIP_withidx.feather\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlb_SR = json_to_dataframe(os.path.normpath(\"../results_blackbox/SR\"))\n",
    "\n",
    "# clean up\n",
    "pmlb_SR.loc[:, \"training_time_hr\"] = pmlb_SR[\"time_time\"] / 3600\n",
    "pmlb_SR[\"r2_zero_test\"] = pmlb_SR[\"r2_test\"].apply(lambda x: max(x, 0))\n",
    "pmlb_SR[\"algorithm\"] = pmlb_SR[\"algorithm\"].apply(lambda x: x.replace(\"Regressor\", \"\"))\n",
    "pmlb_SR[\"algorithm\"] = pmlb_SR[\"algorithm\"].apply(lambda x: x.replace(\"regressor\", \"\"))\n",
    "pmlb_SR[\"algorithm\"] = pmlb_SR[\"algorithm\"].apply(lambda x: x.replace(\"tuned.\", \"\"))\n",
    "pmlb_SR[\"algorithm\"] = pmlb_SR[\"algorithm\"].apply(lambda x: x.replace(\".hclst_v2\", \"\"))\n",
    "pmlb_SR[\"algorithm\"] = pmlb_SR[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"sembackpropgp\", \"SBP-GP\")\n",
    ")\n",
    "pmlb_SR[\"algorithm\"] = pmlb_SR[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"FE_AFP\", \"AFP_FE\")\n",
    ")\n",
    "pmlb_SR[\"algorithm\"] = pmlb_SR[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"GPGOMEA\", \"GP-GOMEA\")\n",
    ")\n",
    "\n",
    "pmlb_SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAN + SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlb_SR_BART = json_to_dataframe(os.path.normpath(\"../results_blackbox/SR_BART_VIP\"))\n",
    "\n",
    "# clean up\n",
    "pmlb_SR_BART.loc[:, \"training_time_hr\"] = pmlb_SR_BART[\"time_time\"] / 3600\n",
    "pmlb_SR_BART[\"r2_zero_test\"] = pmlb_SR_BART[\"r2_test\"].apply(lambda x: max(x, 0))\n",
    "pmlb_SR_BART[\"algorithm\"] = pmlb_SR_BART[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"Regressor\", \"\")\n",
    ")\n",
    "pmlb_SR_BART[\"algorithm\"] = pmlb_SR_BART[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"regressor\", \"\")\n",
    ")\n",
    "pmlb_SR_BART[\"algorithm\"] = pmlb_SR_BART[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"tuned.\", \"\")\n",
    ")\n",
    "pmlb_SR_BART[\"algorithm\"] = pmlb_SR_BART[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\".hclst_v2\", \"\")\n",
    ")\n",
    "pmlb_SR_BART[\"algorithm\"] = pmlb_SR_BART[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"sembackpropgp\", \"SBP-GP\")\n",
    ")\n",
    "pmlb_SR_BART[\"algorithm\"] = pmlb_SR_BART[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"FE_AFP\", \"AFP_FE\")\n",
    ")\n",
    "pmlb_SR_BART[\"algorithm\"] = pmlb_SR_BART[\"algorithm\"].apply(\n",
    "    lambda x: x.replace(\"GPGOMEA\", \"GP-GOMEA\")\n",
    ")\n",
    "\n",
    "pmlb_SR_BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlb_results = pd.concat([pmlb_SR, pmlb_SR_BART], ignore_index=True)\n",
    "pmlb_results\n",
    "\n",
    "feather.write_feather(\n",
    "    pmlb_results,\n",
    "    os.path.normpath(\"../results_blackbox/pmlb_results.feather\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
